{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import copy\n",
    "\n",
    "train = pd.read_csv(\"./cat-in-the-dat/train.csv\", index_col=['id'])\n",
    "test = pd.read_csv(\"./cat-in-the-dat/test.csv\", index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_0      int64\n",
       "bin_1      int64\n",
       "bin_2      int64\n",
       "bin_3     object\n",
       "bin_4     object\n",
       "nom_0     object\n",
       "nom_1     object\n",
       "nom_2     object\n",
       "nom_3     object\n",
       "nom_4     object\n",
       "nom_5     object\n",
       "nom_6     object\n",
       "nom_7     object\n",
       "nom_8     object\n",
       "nom_9     object\n",
       "ord_0      int64\n",
       "ord_1     object\n",
       "ord_2     object\n",
       "ord_3     object\n",
       "ord_4     object\n",
       "ord_5     object\n",
       "day        int64\n",
       "month      int64\n",
       "target     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Bassoon</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "id                                                                        \n",
       "0       0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1       0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2       0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3       0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4       0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "       nom_4  ...      nom_9 ord_0        ord_1        ord_2 ord_3  ord_4  \\\n",
       "id            ...                                                           \n",
       "0    Bassoon  ...  2f4cb3d51     2  Grandmaster         Cold     h      D   \n",
       "1      Piano  ...  f83c56c21     1  Grandmaster          Hot     a      A   \n",
       "2   Theremin  ...  ae6800dd0     1       Expert     Lava Hot     h      R   \n",
       "3       Oboe  ...  8270f0d71     1  Grandmaster  Boiling Hot     i      D   \n",
       "4       Oboe  ...  b164b72a7     1  Grandmaster     Freezing     a      R   \n",
       "\n",
       "   ord_5 day month target  \n",
       "id                         \n",
       "0     kr   2     2      0  \n",
       "1     bF   7     8      0  \n",
       "2     Jc   7     2      0  \n",
       "3     kW   2     1      1  \n",
       "4     qP   7     8      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"target\", axis = 1)\n",
    "y = train.loc[:,\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding for catagory \n",
    "\n",
    "#### Binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1', 'nom_2',\n",
       "       'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_0',\n",
       "       'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.bin_3 = X.bin_3.apply(lambda x: 1 if x == \"T\" else 0)\n",
    "X.bin_4 = X.bin_4.apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "\n",
    "# X = X.drop([\"nom_0\", \"nom_1\", \"nom_2\", \"nom_3\", \"nom_4\"], axis=1) \\\n",
    "#         .join(pd.get_dummies(X[[\"nom_0\", \"nom_1\", \"nom_2\", \"nom_3\", \"nom_4\"]]))\n",
    "\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nominal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = FeatureHasher(input_type='string', n_features=1000)\n",
    "# X[['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']].values\n",
    "# hash_X = h.fit_transform(X[['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']].values)\n",
    "# hash_X = pd.DataFrame(hash_X.toarray())\n",
    "\n",
    "# hash_X.columns\n",
    "\n",
    "# X = X.drop([\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"], axis=1).join(hash_X)\n",
    "\n",
    "# loo_encoder = LeaveOneOutEncoder(cols=[\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"])\n",
    "# loo_X = loo_encoder.fit_transform(X[[\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"]], y)\n",
    "# X = X.drop([\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"], axis=1).join(loo_X)\n",
    "\n",
    "# X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oe = OrdinalEncoder(categories='auto')\n",
    "# df = pd.DataFrame({'foo1': ['a','c','a','a','b','d']})\n",
    "# oe.fit_transform(df.foo1.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X.ord_1.replace(to_replace = ['Novice', 'Contributor','Expert', 'Master', 'Grandmaster'],\n",
    "                         value = [0, 1, 2, 3, 4], inplace = True)\n",
    "X.ord_2.replace(to_replace = ['Freezing', 'Cold', 'Warm', 'Hot','Boiling Hot', 'Lava Hot'],\n",
    "                         value = [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "\n",
    "for i in [\"ord_3\", \"ord_4\"]:\n",
    "   le = LabelEncoder()\n",
    "   X[[i]] = le.fit_transform(X[[i]])\n",
    "\n",
    "oe = OrdinalEncoder(categories='auto')\n",
    "X.ord_5 = oe.fit_transform(X.ord_5.values.reshape(-1,1))\n",
    "\n",
    "#X.columns\n",
    "\n",
    "# X = X.drop([\"ord_3\", \"ord_4\", \"ord_5\"], axis=1) \\\n",
    "#         .join(pd.get_dummies(X[[\"ord_3\", \"ord_4\", \"ord_5\"]]))\n",
    "\n",
    "# X.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_0        int64\n",
       "bin_1        int64\n",
       "bin_2        int64\n",
       "bin_3        int64\n",
       "bin_4        int64\n",
       "             ...  \n",
       "ord_5_yY     uint8\n",
       "ord_5_yc     uint8\n",
       "ord_5_zU     uint8\n",
       "day         object\n",
       "month       object\n",
       "Length: 1268, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"day\",\"month\"]] = X[[\"day\",\"month\"]].astype(\"object\")\n",
    "X.dtypes\n",
    "#pd.get_dummies(X[[\"day\", \"month\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      'bin_0',       'bin_1',       'bin_2',       'bin_3',\n",
       "             'bin_4',       'ord_0',       'ord_1',       'ord_2',\n",
       "        'nom_0_Blue', 'nom_0_Green',\n",
       "       ...\n",
       "           'month_3',     'month_4',     'month_5',     'month_6',\n",
       "           'month_7',     'month_8',     'month_9',    'month_10',\n",
       "          'month_11',    'month_12'],\n",
       "      dtype='object', length=1285)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop([\"day\", \"month\"], axis=1) \\\n",
    "        .join(pd.get_dummies(X[[\"day\", \"month\"]]))\n",
    "\n",
    "X.columns\n",
    "\n",
    "#def date_cyc_enc(df, col, max_vals):\n",
    "#    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n",
    "#    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n",
    "#    return df\n",
    "\n",
    "#X = date_cyc_enc(X, 'day', 7)\n",
    "#X = date_cyc_enc(X, 'month', 12)\n",
    "#X.drop(['day', 'month'], axis=1, inplace = True)\n",
    "\n",
    "#X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data\n",
    "\n",
    "* Tree based models does not depend on scaling\n",
    "* Non-tree based models hugely depend on scaling\n",
    "\n",
    "So if I use linear model, scaling is essential, otherwise not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (300000, 8524) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-c790fd6a2352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (300000, 8524) and data type float64"
     ]
    }
   ],
   "source": [
    "#min_max_scaler = MinMaxScaler()\n",
    "#X_minmax = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_new = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model refinement\n",
    "\n",
    "#### Try it on linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "scores_lr = cross_val_score(lr, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_lr.mean(), scores_lr.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "rc = RidgeClassifier()\n",
    "scores_rc = cross_val_score(rc, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rc.mean(), scores_rc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "scores_lda = cross_val_score(lda, X_new, y, cv=5, n_jobs=1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_lda.mean(), scores_lda.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = LinearSVC(penalty=\"l2\")\n",
    "scores_linear_svm = cross_val_score(linear_svm, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_linear_svm.mean(), scores_linear_svm.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression, RidgeClassifier and LinearDiscriminantAnalysis revel better accuracy than LinearSVC. But if use X insteading of X_new, weather it has still good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that scaled data maybe has better accuracy original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it on classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "fr = DecisionTreeClassifier(random_state=0)\n",
    "scores_dt = cross_val_score(fr, X, y, cv=5, n_jobs=2)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_dt.mean(), scores_dt.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46 (+/- 0.38)\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "scores_sgdc = cross_val_score(sgdc, X, y, cv=5, n_jobs=4)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_sgdc.mean(), scores_sgdc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier()\n",
    "scores_ab= cross_val_score(ab, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_ab.mean(), scores_ab.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "scores_gbm= cross_val_score(gbm, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_gbm.mean(), scores_gbm.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores_rf= cross_val_score(rf, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rf.mean(), scores_rf.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "scores_et= cross_val_score(et, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_et.mean(), scores_et.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "scores_xgb= cross_val_score(xgb, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_xgb.mean(), scores_xgb.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that GradientBoostingClassifier, XGBClassifier maybe have the best accuracy in above methods, which the accuracy of AdaBoostClassifier is also close to. Otherwise, others maybe performent not good.\n",
    "\n",
    "#### Grid Search for best params of XGBClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   55.4s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  2.1min remaining:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([ 47.79684703,  52.27401908, 119.7774841 ,  48.17668215,\n",
      "        57.93815573]), 'std_fit_time': array([ 0.29789206,  0.95753492, 14.84604595,  0.37390398, 12.90913243]), 'mean_score_time': array([0.47573551, 0.54289651, 0.91353989, 0.53941655, 0.51821582]), 'std_score_time': array([0.02845468, 0.00212782, 0.04051057, 0.00586698, 0.07428489]), 'param_subsample': masked_array(data=[0.6, 0.2, 0.8, 0.4, 0.2],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 5, 10, 10, 1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 4, 10, 4, 5],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[1.5, 1.5, 5, 1.5, 1.5],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.8, 0.8, 0.8, 0.6, 1.0],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.2, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.4, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.2, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.76923, 0.78973, 0.87326, 0.79693, 0.80055]), 'split1_test_score': array([0.76556, 0.78355, 0.86834, 0.78735, 0.79883]), 'split2_test_score': array([0.76778, 0.7893 , 0.86123, 0.78972, 0.799  ]), 'mean_test_score': array([0.76752333, 0.78752667, 0.86761   , 0.79133333, 0.79946   ]), 'std_test_score': array([0.00150922, 0.0028174 , 0.00493828, 0.004074  , 0.00077386]), 'rank_test_score': array([5, 4, 1, 3, 2], dtype=int32)}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=5,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=10, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=True, subsample=0.8, verbosity=1)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10, 13, 15],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 20]\n",
    "        }\n",
    "xgb = XGBClassifier(silent=True, nthread=1)\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, \n",
    "                                   scoring='accuracy', n_jobs=-1, cv=skf.split(X, y), \n",
    "                                   verbose=3, random_state=1001 )\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "#results = pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768 (+/-0.003) for {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 3, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
      "0.788 (+/-0.006) for {'subsample': 0.2, 'min_child_weight': 5, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
      "0.868 (+/-0.010) for {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "0.791 (+/-0.008) for {'subsample': 0.4, 'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5, 'colsample_bytree': 0.6}\n",
      "0.799 (+/-0.002) for {'subsample': 0.2, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 1.5, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for best params of GradientBoostingClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed: 67.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([ 908.29501446,  845.39744933, 1648.9516054 ,  731.22689096,\n",
      "        664.19118261]), 'std_fit_time': array([ 94.75944472,  85.08638074, 586.84364353,  32.08922876,\n",
      "       115.58840373]), 'mean_score_time': array([1.55622586, 1.18005204, 1.39842073, 0.71798897, 0.64372404]), 'std_score_time': array([0.50675279, 0.00952958, 0.36244974, 0.00273974, 0.04241387]), 'param_subsample': masked_array(data=[0.6, 0.2, 0.8, 0.4, 0.6],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[800, 100, 300, 100, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[800, 200, 100, 500, 800],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[20, 50, 50, 50, 20],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.5, 0.5, 1, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.6, 'n_estimators': 800, 'min_samples_split': 800, 'max_depth': 20, 'learning_rate': 0.5}, {'subsample': 0.2, 'n_estimators': 100, 'min_samples_split': 200, 'max_depth': 50, 'learning_rate': 0.5}, {'subsample': 0.8, 'n_estimators': 300, 'min_samples_split': 100, 'max_depth': 50, 'learning_rate': 1}, {'subsample': 0.4, 'n_estimators': 100, 'min_samples_split': 500, 'max_depth': 50, 'learning_rate': 0.01}, {'subsample': 0.6, 'n_estimators': 100, 'min_samples_split': 800, 'max_depth': 20, 'learning_rate': 0.01}], 'split0_test_score': array([0.99977, 0.9236 , 0.99629, 0.72516, 0.72349]), 'split1_test_score': array([0.99992, 0.95437, 0.99437, 0.72463, 0.72309]), 'split2_test_score': array([0.99992, 0.91814, 0.95576, 0.72614, 0.72385]), 'mean_test_score': array([0.99987   , 0.93203667, 0.98214   , 0.72531   , 0.72347667]), 'std_test_score': array([7.07106781e-05, 1.59485889e-02, 1.86699384e-02, 6.25513123e-04,\n",
      "       3.10411913e-04]), 'rank_test_score': array([1, 3, 2, 4, 5], dtype=int32)}\n",
      "\n",
      " Best estimator:\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.5, loss='deviance', max_depth=20,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=800,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=800,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=1001, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'n_estimators': 800, 'min_samples_split': 800, 'max_depth': 20, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "params2 = {\n",
    "        'n_estimators': [50, 100, 300, 800],\n",
    "        'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "        'max_depth': [3, 10, 20, 50],\n",
    "        'min_samples_split': [100, 200, 500, 800],\n",
    "        'subsample': [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        }\n",
    "gbm = GradientBoostingClassifier(random_state=1001)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(gbm, param_distributions=params2, n_iter=param_comb, \n",
    "                                   scoring='accuracy', n_jobs=-1, cv=skf.split(X, y), \n",
    "                                   verbose=3, random_state=1001 )\n",
    "random_search2.fit(X, y)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search2.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search2.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search2.best_params_)\n",
    "#results = pd.DataFrame(random_search2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 (+/-0.000) for {'subsample': 0.6, 'n_estimators': 800, 'min_samples_split': 800, 'max_depth': 20, 'learning_rate': 0.5}\n",
      "0.932 (+/-0.032) for {'subsample': 0.2, 'n_estimators': 100, 'min_samples_split': 200, 'max_depth': 50, 'learning_rate': 0.5}\n",
      "0.982 (+/-0.037) for {'subsample': 0.8, 'n_estimators': 300, 'min_samples_split': 100, 'max_depth': 50, 'learning_rate': 1}\n",
      "0.725 (+/-0.001) for {'subsample': 0.4, 'n_estimators': 100, 'min_samples_split': 500, 'max_depth': 50, 'learning_rate': 0.01}\n",
      "0.723 (+/-0.001) for {'subsample': 0.6, 'n_estimators': 100, 'min_samples_split': 800, 'max_depth': 20, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "means = random_search2.cv_results_['mean_test_score']\n",
    "stds = random_search2.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_search2.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for best params of LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   28.7s remaining:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:   40.5s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   44.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([ 8.74004189, 29.41071987, 24.10780462, 22.03874866, 16.1790061 ]), 'std_fit_time': array([0.8806604 , 0.95997239, 1.08362148, 4.4700542 , 0.78093431]), 'mean_score_time': array([0.04158473, 0.02806997, 0.03090366, 0.0189476 , 0.01525704]), 'std_score_time': array([0.00647106, 0.00441646, 0.00413027, 0.00091417, 0.00100142]), 'param_solver': masked_array(data=['lbfgs', 'sag', 'newton-cg', 'sag', 'saga'],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_C': masked_array(data=[0.01, 0.5, 0.01, 0.01, 0.1],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'solver': 'lbfgs', 'C': 0.01}, {'solver': 'sag', 'C': 0.5}, {'solver': 'newton-cg', 'C': 0.01}, {'solver': 'sag', 'C': 0.01}, {'solver': 'saga', 'C': 0.1}], 'split0_test_score': array([0.74299, 0.75941, 0.75857, 0.75665, 0.75495]), 'split1_test_score': array([0.73967, 0.75957, 0.75843, 0.75591, 0.75378]), 'split2_test_score': array([0.74133, 0.75977, 0.75909, 0.75765, 0.75598]), 'mean_test_score': array([0.74133   , 0.75958333, 0.75869667, 0.75673667, 0.75490333]), 'std_test_score': array([0.00135538, 0.00014727, 0.00028394, 0.00071299, 0.00089875]), 'rank_test_score': array([5, 1, 2, 3, 4], dtype=int32)}\n",
      "\n",
      " Best estimator:\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=1001, solver='sag', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'solver': 'sag', 'C': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_params = {'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n",
    "             'C': [0.01, 0.1, 0.5, 1]\n",
    "            }\n",
    "lr = LogisticRegression(random_state=1001)\n",
    "\n",
    "random_search3 = RandomizedSearchCV(lr, param_distributions=lr_params, n_iter=param_comb, \n",
    "                                   scoring='accuracy', n_jobs=-1, cv=skf.split(X, y), \n",
    "                                   verbose=3, random_state=1001 )\n",
    "random_search3.fit(X, y)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search3.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search3.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search3.best_params_)\n",
    "#results = pd.DataFrame(random_search2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.741 (+/-0.003) for {'solver': 'lbfgs', 'C': 0.01}\n",
      "0.760 (+/-0.000) for {'solver': 'sag', 'C': 0.5}\n",
      "0.759 (+/-0.001) for {'solver': 'newton-cg', 'C': 0.01}\n",
      "0.757 (+/-0.001) for {'solver': 'sag', 'C': 0.01}\n",
      "0.755 (+/-0.002) for {'solver': 'saga', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "means = random_search3.cv_results_['mean_test_score']\n",
    "stds = random_search3.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_search3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: xgbclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.5min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: gradientboostingclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 47.1min remaining: 70.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: adaboostclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 238.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 16.1min remaining: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 20.1min finished\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(booster='gbtree', gamma=5, colsample_bytree=0.8,\n",
    "                        learning_rate=0.1, max_depth=10, \n",
    "                        min_child_weight=10, n_estimators=100, \n",
    "                        silent=True, subsample=0.8)\n",
    "\n",
    "ab_clf = AdaBoostClassifier(n_estimators=200,\n",
    "                            base_estimator=DecisionTreeClassifier(\n",
    "                                min_samples_leaf=2,\n",
    "                                random_state=1001),\n",
    "                            random_state=1001)\n",
    "\n",
    "gbm_clf = GradientBoostingClassifier(n_estimators=300, min_samples_split=100,\n",
    "                                 max_depth=50, learning_rate=1, subsample=0.8,\n",
    "                                 random_state=1001)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "stack = StackingCVClassifier(classifiers=[xgb_clf, gbm_clf, ab_clf], \n",
    "                            meta_classifier=lr,\n",
    "                            cv=5,\n",
    "                            stratify=True,\n",
    "                            shuffle=True,\n",
    "                            use_probas=True,\n",
    "                            use_features_in_secondary=True,\n",
    "                            verbose=1,\n",
    "                            random_state=1001,\n",
    "                            n_jobs=-1)\n",
    "stack = stack.fit(X, y)\n",
    "#scores_stack = cross_val_score(stack, X, y, cv=2, n_jobs=-1, scoring='accuracy')\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_stack.mean(), scores_stack.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>9d117320c</td>\n",
       "      <td>3c49b42b8</td>\n",
       "      <td>2</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>j</td>\n",
       "      <td>P</td>\n",
       "      <td>be</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Square</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>46ae3059c</td>\n",
       "      <td>285771075</td>\n",
       "      <td>1</td>\n",
       "      <td>Master</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>l</td>\n",
       "      <td>A</td>\n",
       "      <td>RP</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Square</td>\n",
       "      <td>Dog</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>b759e21f0</td>\n",
       "      <td>6f323c53f</td>\n",
       "      <td>2</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>G</td>\n",
       "      <td>tP</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Cat</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>0b6ec68ff</td>\n",
       "      <td>b5de3dcc4</td>\n",
       "      <td>1</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>b</td>\n",
       "      <td>Q</td>\n",
       "      <td>ke</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Dog</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>f91f3b1ee</td>\n",
       "      <td>967cfa9c9</td>\n",
       "      <td>3</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>l</td>\n",
       "      <td>W</td>\n",
       "      <td>qK</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2    nom_3  \\\n",
       "id                                                                           \n",
       "300000      0      0      1     T     Y  Blue   Triangle  Axolotl  Finland   \n",
       "300001      0      0      0     T     N   Red     Square     Lion   Canada   \n",
       "300002      1      0      1     F     Y  Blue     Square      Dog    China   \n",
       "300003      0      0      1     T     Y   Red       Star      Cat    China   \n",
       "300004      0      1      1     F     N   Red  Trapezoid      Dog    China   \n",
       "\n",
       "        nom_4  ...      nom_8      nom_9 ord_0        ord_1     ord_2  ord_3  \\\n",
       "id             ...                                                             \n",
       "300000  Piano  ...  9d117320c  3c49b42b8     2       Novice      Warm      j   \n",
       "300001  Piano  ...  46ae3059c  285771075     1       Master  Lava Hot      l   \n",
       "300002  Piano  ...  b759e21f0  6f323c53f     2       Expert  Freezing      a   \n",
       "300003  Piano  ...  0b6ec68ff  b5de3dcc4     1  Contributor  Lava Hot      b   \n",
       "300004  Piano  ...  f91f3b1ee  967cfa9c9     3  Grandmaster  Lava Hot      l   \n",
       "\n",
       "       ord_4 ord_5 day month  \n",
       "id                            \n",
       "300000     P    be   5    11  \n",
       "300001     A    RP   7     5  \n",
       "300002     G    tP   1    12  \n",
       "300003     Q    ke   2     3  \n",
       "300004     W    qK   4    11  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = copy.deepcopy(test)\n",
    "\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_test.bin_3 = X_test.bin_3.apply(lambda x: 1 if x == \"T\" else 0)\n",
    "X_test.bin_4 = X_test.bin_4.apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "\n",
    "# X_test = X_test.drop([\"nom_0\", \"nom_1\", \"nom_2\", \"nom_3\", \"nom_4\"], axis=1) \\\n",
    "#         .join(pd.get_dummies(X_test[[\"nom_0\", \"nom_1\", \"nom_2\", \"nom_3\", \"nom_4\"]]))\n",
    "\n",
    "# loo_X_test = loo_encoder.transform(X_test[[\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"]])\n",
    "# X_test = X_test.drop([\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"], axis=1).join(loo_X_test)\n",
    "\n",
    "X_test.ord_1.replace(to_replace = ['Novice', 'Contributor','Expert', 'Master', 'Grandmaster'],\n",
    "                         value = [0, 1, 2, 3, 4], inplace = True)\n",
    "X_test.ord_2.replace(to_replace = ['Freezing', 'Cold', 'Warm', 'Hot','Boiling Hot', 'Lava Hot'],\n",
    "                         value = [0, 1, 2, 3, 4, 5], inplace = True)\n",
    "\n",
    "# X_test = X_test.drop([\"ord_3\", \"ord_4\", \"ord_5\"], axis=1) \\\n",
    "#         .join(pd.get_dummies(X_test[[\"ord_3\", \"ord_4\", \"ord_5\"]]))\n",
    "\n",
    "# X_test = X_test.drop([\"day\", \"month\"], axis=1) \\\n",
    "#         .join(pd.get_dummies(X_test[[\"day\", \"month\"]]))\n",
    "\n",
    "\n",
    "for i in [\"ord_3\", \"ord_4\"]:\n",
    "    le = LabelEncoder()\n",
    "    X_test[[i]] = le.fit_transform(X_test[[i]])\n",
    "\n",
    "oe = OrdinalEncoder(categories='auto')\n",
    "X_test.ord_5 = oe.fit_transform(X_test.ord_5.values.reshape(-1,1))\n",
    "\n",
    "# X_test = date_cyc_enc(X_test, 'day', 7)\n",
    "# X_test = date_cyc_enc(X_test, 'month', 12)\n",
    "# X_test.drop(['day', 'month'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.ord_5.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.ord_5.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>9d117320c</td>\n",
       "      <td>3c49b42b8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>Square</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>46ae3059c</td>\n",
       "      <td>285771075</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Square</td>\n",
       "      <td>Dog</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>b759e21f0</td>\n",
       "      <td>6f323c53f</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Cat</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>0b6ec68ff</td>\n",
       "      <td>b5de3dcc4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Dog</td>\n",
       "      <td>China</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>f91f3b1ee</td>\n",
       "      <td>967cfa9c9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>157.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin_0  bin_1  bin_2  bin_3  bin_4 nom_0      nom_1    nom_2    nom_3  \\\n",
       "id                                                                             \n",
       "300000      0      0      1      1      1  Blue   Triangle  Axolotl  Finland   \n",
       "300001      0      0      0      1      0   Red     Square     Lion   Canada   \n",
       "300002      1      0      1      0      1  Blue     Square      Dog    China   \n",
       "300003      0      0      1      1      1   Red       Star      Cat    China   \n",
       "300004      0      1      1      0      0   Red  Trapezoid      Dog    China   \n",
       "\n",
       "        nom_4  ...      nom_8      nom_9 ord_0 ord_1 ord_2  ord_3  ord_4  \\\n",
       "id             ...                                                         \n",
       "300000  Piano  ...  9d117320c  3c49b42b8     2     0     2      9     15   \n",
       "300001  Piano  ...  46ae3059c  285771075     1     3     5     11      0   \n",
       "300002  Piano  ...  b759e21f0  6f323c53f     2     2     0      0      6   \n",
       "300003  Piano  ...  0b6ec68ff  b5de3dcc4     1     1     5      1     16   \n",
       "300004  Piano  ...  f91f3b1ee  967cfa9c9     3     4     5     11     22   \n",
       "\n",
       "        ord_5  day  month  \n",
       "id                         \n",
       "300000   95.0    5     11  \n",
       "300001   61.0    7      5  \n",
       "300002  172.0    1     12  \n",
       "300003  135.0    2      3  \n",
       "300004  157.0    4     11  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 23)\n",
      "(200000, 23)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(\"bin_0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 23)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_0     int64\n",
       "bin_1     int64\n",
       "bin_2     int64\n",
       "bin_3    object\n",
       "bin_4    object\n",
       "nom_0    object\n",
       "nom_1    object\n",
       "nom_2    object\n",
       "nom_3    object\n",
       "nom_4    object\n",
       "nom_5    object\n",
       "nom_6    object\n",
       "nom_7    object\n",
       "nom_8    object\n",
       "nom_9    object\n",
       "ord_0     int64\n",
       "ord_1    object\n",
       "ord_2    object\n",
       "ord_3    object\n",
       "ord_4    object\n",
       "ord_5    object\n",
       "day       int64\n",
       "month     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns\n",
    "dummies = pd.get_dummies(data,\n",
    "                         columns=columns,\n",
    "#                          drop_first=True,\n",
    "                         sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 16552)\n"
     ]
    }
   ],
   "source": [
    "print(dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies.iloc[:X.shape[0], :]\n",
    "X_test = dummies.iloc[X.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 16552)\n",
      "(200000, 16552)\n"
     ]
    }
   ],
   "source": [
    "del dummies\n",
    "del data\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0_0</th>\n",
       "      <th>bin_0_1</th>\n",
       "      <th>bin_1_0</th>\n",
       "      <th>bin_1_1</th>\n",
       "      <th>bin_2_0</th>\n",
       "      <th>bin_2_1</th>\n",
       "      <th>bin_3_F</th>\n",
       "      <th>bin_3_T</th>\n",
       "      <th>bin_4_N</th>\n",
       "      <th>bin_4_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin_0_0  bin_0_1  bin_1_0  bin_1_1  bin_2_0  bin_2_1  bin_3_F  bin_3_T  \\\n",
       "id                                                                           \n",
       "0         1        0        1        0        1        0        0        1   \n",
       "1         1        0        0        1        1        0        0        1   \n",
       "2         1        0        1        0        1        0        1        0   \n",
       "3         1        0        0        1        1        0        1        0   \n",
       "4         1        0        1        0        1        0        1        0   \n",
       "\n",
       "    bin_4_N  bin_4_Y  ...  month_3  month_4  month_5  month_6  month_7  \\\n",
       "id                    ...                                                \n",
       "0         0        1  ...        0        0        0        0        0   \n",
       "1         0        1  ...        0        0        0        0        0   \n",
       "2         0        1  ...        0        0        0        0        0   \n",
       "3         0        1  ...        0        0        0        0        0   \n",
       "4         1        0  ...        0        0        0        0        0   \n",
       "\n",
       "    month_8  month_9  month_10  month_11  month_12  \n",
       "id                                                  \n",
       "0         0        0         0         0         0  \n",
       "1         1        0         0         0         0  \n",
       "2         0        0         0         0         0  \n",
       "3         0        0         0         0         0  \n",
       "4         1        0         0         0         0  \n",
       "\n",
       "[5 rows x 16552 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sparse.to_coo().tocsr()\n",
    "X_test = X_test.sparse.to_coo().tocsr()\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array(X_test)\n",
    "#pred = stack.predict(X_test)\n",
    "pred = stack.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.60453924e-01, 4.15311686e-01, 9.71599955e-01, 1.90172725e-01,\n",
       "       1.93344159e-04, 1.47929063e-03, 8.76056952e-03, 1.25936934e-02,\n",
       "       9.90136422e-01, 4.93963888e-05])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_4_Theremin</th>\n",
       "      <th>nom_5</th>\n",
       "      <th>nom_6</th>\n",
       "      <th>nom_7</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327116</td>\n",
       "      <td>0.330645</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-9.749279e-01</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329803</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.389796</td>\n",
       "      <td>0.222707</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336677</td>\n",
       "      <td>0.305964</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328419</td>\n",
       "      <td>0.244373</td>\n",
       "      <td>0.361022</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>9.749279e-01</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243365</td>\n",
       "      <td>0.330569</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>-4.338837e-01</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin_0  bin_1  bin_2  bin_3  bin_4  ord_0  ord_1  ord_2  ord_3  ord_4  \\\n",
       "id                                                                             \n",
       "300000      0      0      1      1      1      2      0      2      9     15   \n",
       "300001      0      0      0      1      0      1      3      5     11      0   \n",
       "300002      1      0      1      0      1      2      2      0      0      6   \n",
       "300003      0      0      1      1      1      1      1      5      1     16   \n",
       "300004      0      1      1      0      0      3      4      5     11     22   \n",
       "\n",
       "        ...  nom_4_Theremin     nom_5     nom_6     nom_7     nom_8     nom_9  \\\n",
       "id      ...                                                                     \n",
       "300000  ...               0  0.327116  0.330645  0.299065  0.348315  0.181818   \n",
       "300001  ...               0  0.329803  0.399600  0.389796  0.222707  0.288889   \n",
       "300002  ...               0  0.336677  0.305964  0.317597  0.186667  0.090909   \n",
       "300003  ...               0  0.328419  0.244373  0.361022  0.360656  0.320000   \n",
       "300004  ...               0  0.243365  0.330569  0.271300  0.375000  0.294118   \n",
       "\n",
       "             day_sin   day_cos     month_sin     month_cos  \n",
       "id                                                          \n",
       "300000 -9.749279e-01 -0.222521 -5.000000e-01  8.660254e-01  \n",
       "300001 -2.449294e-16  1.000000  5.000000e-01 -8.660254e-01  \n",
       "300002  7.818315e-01  0.623490 -2.449294e-16  1.000000e+00  \n",
       "300003  9.749279e-01 -0.222521  1.000000e+00  6.123234e-17  \n",
       "300004 -4.338837e-01 -0.900969 -5.000000e-01  8.660254e-01  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=5,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=10, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=True, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf2 = XGBClassifier(booster='gbtree', gamma=5, colsample_bytree=0.8,\n",
    "                        learning_rate=0.1, max_depth=10, \n",
    "                        min_child_weight=10, n_estimators=100, \n",
    "                        silent=True, subsample=0.8, n_jobs=-1)\n",
    "xgb_clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = xgb_clf2.predict(X_test)\n",
    "pred2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None, learning_rate=1,\n",
       "                           loss='deviance', max_depth=50, max_features=None,\n",
       "                           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                           min_impurity_split=None, min_samples_leaf=1,\n",
       "                           min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
       "                           n_estimators=300, n_iter_no_change=None,\n",
       "                           presort='auto', random_state=1001, subsample=0.8,\n",
       "                           tol=0.0001, validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_clf2 = GradientBoostingClassifier(n_estimators=300, min_samples_split=100,\n",
    "                                 max_depth=50, learning_rate=1, subsample=0.8,\n",
    "                                 random_state=1001)\n",
    "gbm_clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = gbm_clf2.predict(X_test)\n",
    "pred3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23799456, 0.65998172, 0.07750979, 0.47985296, 0.82529916,\n",
       "       0.16685068, 0.4914223 , 0.16917902, 0.44640971, 0.51153191])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = pipe.predict_proba(X_test)\n",
    "pred4[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'ord_0', 'ord_1', 'ord_2',\n",
       "       'ord_3', 'ord_4', 'ord_5', 'nom_0_Blue', 'nom_0_Green', 'nom_0_Red',\n",
       "       'nom_1_Circle', 'nom_1_Polygon', 'nom_1_Square', 'nom_1_Star',\n",
       "       'nom_1_Trapezoid', 'nom_1_Triangle', 'nom_2_Axolotl', 'nom_2_Cat',\n",
       "       'nom_2_Dog', 'nom_2_Hamster', 'nom_2_Lion', 'nom_2_Snake',\n",
       "       'nom_3_Canada', 'nom_3_China', 'nom_3_Costa Rica', 'nom_3_Finland',\n",
       "       'nom_3_India', 'nom_3_Russia', 'nom_4_Bassoon', 'nom_4_Oboe',\n",
       "       'nom_4_Piano', 'nom_4_Theremin', 'nom_5', 'nom_6', 'nom_7', 'nom_8',\n",
       "       'nom_9', 'day_sin', 'day_cos', 'month_sin', 'month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X.drop([\"nom_5\", \"nom_6\", \"nom_7\", \"nom_8\", \"nom_9\"])\n",
    "#len(X.columns)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-48b7f6affe59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#display(X[[\"bin_0\",\"bin_1\"]].head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#colnames = X.columns[:36]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#X.columns[:36]\n",
    "#display(X[[\"bin_0\",\"bin_1\"]].head())\n",
    "#colnames = X.columns[:36]\n",
    "display(X[X.columns[:36]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23709502, 0.6487434 , 0.07883924, 0.47918679, 0.82513343,\n",
       "       0.17479619, 0.49127036, 0.16852144, 0.44993832, 0.50750788])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#lr = LogisticRegression(penalty=\"l1\")\n",
    "lr = LogisticRegressionCV()\n",
    "lr.fit(X, y)\n",
    "pred5 = lr.predict_proba(X_test)\n",
    "#lr.fit(X[X.columns[:36]], y)\n",
    "#pred5 = lr.predict_proba(X_test[X_test.columns[:36]])\n",
    "pred5[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 classifiers...\n",
      "Fitting classifier1: pipeline (1/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.7s remaining:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: pipeline (2/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.8s remaining:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.0s finished\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anlan/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), LogisticRegression(solver=\"lbfgs\", C=0.1, max_iter=10000))\n",
    "\n",
    "pipe2 = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\n",
    "\n",
    "#pipe3 = make_pipeline(StandardScaler(), RidgeClassifier())\n",
    "pipe3 = make_pipeline(StandardScaler(), LogisticRegressionCV())\n",
    "\n",
    "stack = StackingCVClassifier(classifiers=[pipe2, pipe3], \n",
    "                            meta_classifier=pipe1,\n",
    "                            cv=5,\n",
    "                            stratify=True,\n",
    "                            shuffle=True,\n",
    "                            use_probas=True,\n",
    "                            use_features_in_secondary=True,\n",
    "                            verbose=1,\n",
    "                            random_state=1001,\n",
    "                            n_jobs=-1)\n",
    "stack = stack.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24753769, 0.64842445, 0.07136907, 0.48044456, 0.81981137,\n",
       "       0.17072148, 0.49109343, 0.1729329 , 0.45016073, 0.50994484])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = stack.predict_proba(X_test)\n",
    "pred6[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31251142, 0.5769731 , 0.09751631, 0.46268508, 0.8777967 ,\n",
       "       0.14889053, 0.51918307, 0.1657425 , 0.39592094, 0.50175138])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = make_pipeline(LogisticRegression(solver=\"lbfgs\", C=0.1, max_iter=10000))\n",
    "pipe1.fit(X, y)\n",
    "pred7 = pipe1.predict_proba(X_test)\n",
    "pred7[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'ord_0', 'ord_1', 'ord_2',\n",
       "       'nom_0_Blue', 'nom_0_Green',\n",
       "       ...\n",
       "       'ord_5_wu', 'ord_5_wy', 'ord_5_xP', 'ord_5_xy', 'ord_5_yN', 'ord_5_yY',\n",
       "       'ord_5_yc', 'ord_5_zU', 'day', 'month'],\n",
       "      dtype='object', length=273)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n",
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    261749\n",
       "1     38251\n",
       "Name: bin_0, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.bin_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208236\n",
       "1     91764\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_test.columns\n",
    "X_test = pd.get_dummies(X_test,\n",
    "                   columns=columns,\n",
    "                   drop_first=True,\n",
    "                   sparse=True)\n",
    "X_test = X_test.sparse.to_coo().tocsr()\n",
    "X_test = X_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 16438)\n",
      "(200000, 16294)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29431422, 0.69282506, 0.07316665, 0.38696786, 0.90706751,\n",
       "       0.17576176, 0.61499651, 0.16726831, 0.35722841, 0.39207942])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe8 = make_pipeline(LogisticRegression())\n",
    "pipe8.fit(X, y)\n",
    "pred8 = pipe8.predict_proba(X_test)\n",
    "pred8[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33811315, 0.69877656, 0.12599665, 0.42130556, 0.86118582,\n",
       "       0.16536373, 0.47803139, 0.17105752, 0.45641044, 0.40366503])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"lbfgs\", C=0.1, max_iter=10000)\n",
    "lr.fit(X, y)\n",
    "pred9 = lr.predict_proba(X_test)\n",
    "pred9[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34115138, 0.68599922, 0.12436068, 0.42224041, 0.86394186,\n",
       "       0.16683914, 0.48127332, 0.15989305, 0.45831126, 0.4061595 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"lbfgs\", C=0.1, max_iter=10000)\n",
    "lr.fit(X, y)\n",
    "pred10 = lr.predict_proba(X_test)\n",
    "pred10[:10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.pop('target')\n",
    "labels = labels.values\n",
    "# train_id = train.pop(\"id\")\n",
    "# test_id = test.pop(\"id\")\n",
    "\n",
    "data = pd.concat([train, test])\n",
    "data[\"ord_5a\"] = data[\"ord_5\"].str[0]\n",
    "data[\"ord_5b\"] = data[\"ord_5\"].str[1]\n",
    "data.drop([\"bin_0\", \"ord_5\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in data.columns]\n",
    "\n",
    "dummies = pd.get_dummies(data,\n",
    "                         columns=columns,\n",
    "                         drop_first=True,\n",
    "                         sparse=True)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dummies.iloc[:train.shape[0], :]\n",
    "test = dummies.iloc[train.shape[0]:, :]\n",
    "\n",
    "del dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 16438)\n",
      "(200000, 16438)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = pd.read_csv(\"./cat-in-the-dat/test.csv\", index_col='id')\n",
    "predictions = pd.Series(pred10[:,1], index=test.index, dtype=y.dtype)\n",
    "predictions.to_csv(\"./cat-in-the-dat/submission10.csv\", header=['target'], index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
